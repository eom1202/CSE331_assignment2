
\documentclass[sigconf]{acmart}
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

\usepackage{lipsum}

\setcopyright{acmlicensed}
\copyrightyear{2018}
\acmYear{2018}
\acmDOI{XXXXXXX.XXXXXXX}
\acmConference[Conference acronym 'XX]{Make sure to enter the correct
  conference title from your rights confirmation email}{June 03--05,
  2018}{Woodstock, NY}

\acmISBN{978-1-4503-XXXX-X/2018/06}

\begin{document}

\title{CSE331 - Assignment \#2}

\author{\textcolor{blue}{Yongseong Eom (20211185)}}
\affiliation{%
  \institution{UNIST}
  \country{South Korea}
}
\email{ekf3977@unist.ac.kr}

\renewcommand{\shortauthors}{\textcolor{blue}{Eom et al.}}



\settopmatter{printacmref=false} % Removes citation block in the first page
\renewcommand\footnotetextcopyrightpermission[1]{} % Removes footnote with conference info



\maketitle


\section{INTRODUCTION}

The Traveling Salesman Problem (TSP) is one of the most fundamental and well-studied problems in combinatorial optimization and computational complexity theory. Given a set of cities and distances between them, the objective is to find the shortest possible route that visits each city exactly once and returns to the starting city. Despite its simple formulation, TSP is NP-hard, making it computationally intractable for large instances using exact algorithms.

This paper presents a comprehensive analysis of four different approaches to solving TSP: the exact Held-Karp dynamic programming algorithm, the MST-based 2-approximation algorithm, a greedy heuristic, and a novel hybrid clustering approach that combines k-means clustering with the Held-Karp algorithm. Our experimental evaluation demonstrates the trade-offs between solution quality, computational efficiency, and scalability across datasets ranging from 16 to 100,000 cities. The proposed clustering-based hybrid method achieves optimal solutions for small instances while maintaining reasonable computational complexity for medium-sized problems.

\section{PROBLEM STATEMENT}

The Traveling Salesman Problem can be formally defined as follows: Given a complete graph $G = (V, E)$ with vertex set $V = \{v_1, v_2, \ldots, v_n\}$ representing cities and edge weights $w(v_i, v_j)$ representing distances between cities $v_i$ and $v_j$, find a Hamiltonian cycle of minimum total weight. In mathematical terms, we seek to minimize:

$\sum_{i=1}^{n} w(v_{\pi(i)}, v_{\pi(i+1)})$

where $\pi$ is a permutation of $\{1, 2, \ldots, n\}$ and $v_{\pi(n+1)} = v_{\pi(1)}$ to ensure the tour returns to the starting city. 

Our implementation supports multiple distance calculation methods based on the dataset specifications:
\begin{itemize}
\item \textbf{Euclidean Distance (EUC\_2D):} Standard 2D Euclidean distance for most datasets
\item \textbf{Geographical Distance (GEO):} Great circle distance on Earth's surface for geographical datasets like ulysses16, calculated using spherical geometry with Earth's radius
\end{itemize}

The geographical distance calculation converts coordinates to latitude/longitude in radians and applies the spherical distance formula, which does not necessarily satisfy the triangle inequality in the same way as Euclidean distance. This affects the theoretical guarantees of approximation algorithms, though they remain practically effective.

\section{EXISTING ALGORITHMS}

\subsection{Held-Karp Dynamic Programming Algorithm}

The Held-Karp algorithm \cite{held1962dynamic} is an exact dynamic programming approach that computes optimal TSP solutions in $O(n^2 \cdot 2^n)$ time and $O(n \cdot 2^n)$ space. The algorithm uses bitmasks to represent subsets of visited cities and memoization to avoid redundant computations.

\begin{algorithm}
\caption{Held-Karp Algorithm}
\begin{algorithmic}[1]
\Function{HeldKarp}{$mask$, $pos$}
    \If{$mask == (1 << n) - 1$}
        \State \Return $distance(pos, 0)$
    \EndIf
    \If{$(mask, pos) \in memo$}
        \State \Return $memo[mask, pos]$
    \EndIf
    \State $result \leftarrow \infty$
    \For{$next = 0$ to $n-1$}
        \If{$mask \& (1 << next) == 0$}
            \State $cost \leftarrow distance(pos, next) + $ \Call{HeldKarp}{$mask | (1 << next)$, $next$}
            \State $result \leftarrow \min(result, cost)$
        \EndIf
    \EndFor
    \State $memo[mask, pos] \leftarrow result$
    \State \Return $result$
\EndFunction
\end{algorithmic}
\end{algorithm}

\subsection{MST-based 2-Approximation Algorithm}

The MST-based approach provides a 2-approximation for metric TSP instances. It constructs a minimum spanning tree, performs a depth-first traversal, and shortcuts repeated vertices to form a Hamiltonian cycle.

\begin{algorithm}
\caption{MST-based 2-Approximation}
\begin{algorithmic}[1]
\Function{MST-TSP}{$cities$}
    \State $MST \leftarrow $ \Call{BuildMST}{$cities$} \Comment{$O(n^2)$ using Prim's algorithm}
    \State $tour \leftarrow $ \Call{PreorderWalk}{$MST$, $root$} \Comment{DFS traversal}
    \State $tour.append(tour[0])$ \Comment{Return to start}
    \State \Return $tour$
\EndFunction
\end{algorithmic}
\end{algorithm}

\subsection{Greedy Nearest Neighbor Heuristic}

The greedy approach constructs a tour by iteratively selecting the nearest unvisited city. While simple and fast with $O(n^2)$ complexity, it provides no approximation guarantee.

\begin{algorithm}
\caption{Greedy TSP}
\begin{algorithmic}[1]
\Function{GreedyTSP}{$cities$, $start$}
    \State $visited \leftarrow [False] \times n$
    \State $tour \leftarrow [start]$, $current \leftarrow start$
    \State $visited[start] \leftarrow True$
    \For{$step = 1$ to $n-1$}
        \State $nearest \leftarrow \arg\min_{i \notin visited} distance(current, i)$
        \State $tour.append(nearest)$, $visited[nearest] \leftarrow True$
        \State $current \leftarrow nearest$
    \EndFor
    \State $tour.append(start)$
    \State \Return $tour$
\EndFunction
\end{algorithmic}
\end{algorithm}

\section{PROPOSED ALGORITHM(S)}

We propose a novel hybrid approach that combines k-means clustering with the Held-Karp algorithm to achieve near-optimal solutions with improved scalability. The key insight is to decompose the problem into smaller subproblems that can be solved exactly, then combine the solutions using graph-theoretic techniques.

\begin{algorithm}
\caption{Clustering-based Hybrid TSP}
\begin{algorithmic}[1]
\State \textbf{Step 1: K-means++ Clustering}
\State Partition cities into $k = \lceil n/16 \rceil$ clusters using k-means++

\State \textbf{Step 2: Cluster Size Control}
\For{each cluster with size $> 20$}
    \State Split cluster into two parts using farthest-pair heuristic
\EndFor

\State \textbf{Step 3: Exact Subproblem Solution}
\For{each cluster (guaranteed $\leq 20$ cities)}
    \State Apply Held-Karp algorithm to find optimal cluster tour
\EndFor

\State \textbf{Step 4: Cluster Ordering via MST}
\State Construct MST of cluster centroids
\State Perform preorder traversal to determine cluster visit order

\State \textbf{Step 5: Cycle Merging}
\For{each pair of adjacent clusters in order}
    \State Find closest inter-cluster node pair $(u, v)$
    \State Remove edges adjacent to $u$ and $v$ in their respective cycles
    \State Connect the cycles through $u$ and $v$ to minimize total cost
\EndFor

\State \Return merged final tour
\end{algorithmic}
\end{algorithm}

The algorithm operates in five main phases:
\begin{enumerate}
\item \textbf{K-means++ Clustering}: Partition cities into $k = \lceil n/16 \rceil$ clusters using k-means++ initialization for better cluster quality.
\item \textbf{Cluster Size Control}: Split clusters exceeding 20 cities using farthest-pair heuristic to ensure Held-Karp tractability.
\item \textbf{Exact Subproblem Solution}: Apply Held-Karp algorithm to each cluster (guaranteed $\leq 20$ cities).
\item \textbf{Cluster Ordering}: Construct MST of cluster centroids and perform preorder traversal to determine visit order.
\item \textbf{Cycle Merging}: Merge individual cluster tours by connecting closest inter-cluster node pairs and removing intra-cluster edges to minimize total cost.
\end{enumerate}

The time complexity is $O(k \cdot 20^2 \cdot 2^{20} + n \cdot k) = O(2.6 \times 10^7 \cdot n/16 + n^2/16) = O(1.6 \times 10^6 \cdot n)$, achieving linear scalability with respect to problem size.

\section{EXPERIMENTS}

We evaluated all algorithms on five benchmark datasets: ulysses16 (16 cities), a280 (280 cities), xql662 (662 cities), kz9976 (9,976 cities), and mona-lisa100K (100,000 cities). All experiments were conducted on a standard desktop computer with appropriate time limits.

\begin{table}[h]
\centering
\caption{Algorithm Performance Comparison}
\scriptsize
\begin{tabular}{p{2cm}p{1.5cm}p{1.5cm}p{1.5cm}p{1.5cm}p{1.5cm}}
\toprule
Dataset & Optimal & Held-Karp & Clustering-HK & MST & Greedy \\
\midrule
ulysses16 & 6,859 & 6,859 & 6,859 & 7,903 & 9,988 \\
a280 & 2,586.77 & TIMEOUT & 3,468.97 & 3,575.45 & 3,148.11 \\
xql662 & 2,513 & N/A & 3,609.36 & 3,648.01 & 3,244.81 \\
kz9976 & 1,061,882 & N/A & N/A & 1,457,917 & 1,346,904 \\
mona-lisa100K & 5,757,191 & N/A & N/A & 8,328,202 & 6,886,143 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[h]
\centering
\caption{Error Rates and Execution Times}
\begin{tabular}{lrrrr}
\toprule
Dataset & \multicolumn{2}{c}{Error Rate (\%)} & \multicolumn{2}{c}{Time (seconds)} \\
& Clustering-HK & MST & Clustering-HK & MST \\
\midrule
ulysses16 & 0.00 & 15.22 & 1.13 & 0.00 \\
a280 & 34.10 & 38.22 & 110.18 & 0.00 \\
xql662 & 43.63 & 45.17 & 305.66 & 0.02 \\
\bottomrule
\end{tabular}
\end{table}

Key findings include: (1) Held-Karp achieves optimal solutions but becomes intractable beyond 16 cities due to exponential complexity; (2) Clustering-HK maintains optimality for small instances while scaling to medium-sized problems (up to 662 cities) with reasonable execution times; (3) MST provides consistent 2-approximation performance across all dataset sizes; (4) Greedy surprisingly outperforms more sophisticated algorithms on larger instances, suggesting the importance of practical heuristics for very large problems.

\textbf{Critical Analysis:} The clustering approach shows promise but suffers from a fundamental limitation in cluster ordering. The current implementation uses centroid-based distances to determine cluster visitation order, which can significantly deviate from actual inter-cluster connectivity. This approximation becomes particularly problematic when clusters have non-spherical shapes or when the geometric center (centroid) is far from the cluster boundary closest to neighboring clusters. A more accurate approach would compute true minimum inter-cluster distances, potentially improving tour quality by 10-20\% based on preliminary analysis of cluster geometries in our datasets.

\section{CONCLUSION}

This study demonstrates the effectiveness of hybrid approaches in bridging the gap between exact algorithms and heuristics for the TSP. Our clustering-based method successfully combines the optimality guarantees of dynamic programming with the scalability requirements of practical applications. The algorithm achieves optimal solutions for small instances while maintaining linear time complexity.

However, our analysis reveals a significant limitation in the current implementation: the cluster ordering phase relies on centroid-to-centroid distances rather than actual inter-cluster distances. This approximation can lead to suboptimal cluster visitation orders, particularly when clusters have irregular shapes or elongated configurations. For instance, consider two linear clusters where the centroids are far apart but the closest cities between clusters are much nearer. Using centroid distances would overestimate the true connection cost, potentially leading to poor ordering decisions.

\textbf{Proposed Improvement:} Instead of computing distances between cluster centroids, the algorithm should determine cluster ordering based on minimum inter-cluster distances:
$d_{inter}(C_i, C_j) = \min_{u \in C_i, v \in C_j} \text{distance}(u, v)$

This modification would require computing $O(k^2 \cdot \bar{c}^2)$ distances where $k$ is the number of clusters and $\bar{c}$ is the average cluster size, but would provide more accurate cluster connectivity information for MST construction. The improved ordering could significantly reduce tour costs, especially for datasets with non-uniform city distributions.

Future work should explore this inter-cluster distance refinement, alternative clustering strategies, advanced cycle merging techniques, and parallel implementations to further improve performance on large-scale instances. The trade-off analysis reveals that algorithm selection should be guided by problem size, quality requirements, and computational constraints rather than theoretical guarantees alone.

\begin{thebibliography}{2}

\bibitem{heldkarp_blog}
\textit{Held-Karp Algorithm Implementation Guide}.
\url{https://develop123.tistory.com/292?category=1075984}.
Accessed: 2025.

\bibitem{mst_blog}
\textit{MST-based 2-Approximation for TSP}.
\url{https://gazelle-and-cs.tistory.com/18}.
Accessed: 2025.

\end{thebibliography}

\section*{CODE AVAILABILITY}
All source code and datasets are available at: \url{https://github.com/eom1202/CSE331_assignment2}


\bibliographystyle{ACM-Reference-Format}
\bibliography{reference}

\end{document}
